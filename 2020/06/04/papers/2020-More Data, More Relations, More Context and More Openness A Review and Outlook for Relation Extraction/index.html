<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"monsterjang.github.io",root:"/",scheme:"Pisces",version:"7.7.1",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="摘要Relational facts are an important component of human knowledge, which are hidden in vast amounts of text. In order to extract these facts from text, people have been working on relation extraction"><meta property="og:type" content="article"><meta property="og:title" content="2020-More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction"><meta property="og:url" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/index.html"><meta property="og:site_name" content="M1saki"><meta property="og:description" content="摘要Relational facts are an important component of human knowledge, which are hidden in vast amounts of text. In order to extract these facts from text, people have been working on relation extraction"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200520154804497.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521163831666.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521164416374.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521170849835.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521170909088.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521171507693.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521171942728.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522172838258.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522181458763.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522220121510.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522220242588.png"><meta property="og:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522221910288.png"><meta property="article:published_time" content="2020-06-04T08:37:41.000Z"><meta property="article:modified_time" content="2020-11-29T08:19:28.161Z"><meta property="article:author" content="M1saki"><meta property="article:tag" content="paper"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200520154804497.png"><link rel="canonical" href="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0}</script><title>2020-More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction | M1saki</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">M1saki</span> <span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="fa fa-fw fa-heartbeat"></i>公益 404</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://monsterjang.github.io/2020/06/04/papers/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar_1.jpg"><meta itemprop="name" content="M1saki"><meta itemprop="description" content="不要低估你的能力<br>不要高估你的毅力"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="M1saki"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">2020-More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-06-04 16:37:41" itemprop="dateCreated datePublished" datetime="2020-06-04T16:37:41+08:00">2020-06-04</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-11-29 16:19:28" itemprop="dateModified" datetime="2020-11-29T16:19:28+08:00">2020-11-29</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/papers/" itemprop="url" rel="index"><span itemprop="name">papers</span></a></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>36k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>33 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h2><blockquote><p>Relational facts are an important component of human knowledge, which are hidden in vast amounts of text. In order to extract these facts from text, people have been working on relation extraction (RE) for years. From early pattern matching to current neural networks, existing RE methods have achieved signiﬁcant progress. Yet with explosion of Web text and emergence of new relations, human knowledge is increasing drastically, and we thus require “more” from RE: a more powerful RE system that can robustly utilize more data, efﬁciently learn more relations, easily handle more complicated context, and ﬂexibly generalize to more open domains. In this paper, we look back at existing RE methods, analyze key challenges we are facing nowadays, and show promising directions towards more powerful RE. We hope our view can advance this ﬁeld and inspire more efforts in the community.</p></blockquote><p>关系事实是人类知识的重要组成部分，隐藏在大量文本中。 为了从文本中提取这些事实，人们多年来一直在进行关系提取（RE）。 从早期的模式匹配到当前的神经网络，现有的RE方法已经取得了重大进展。 但是，随着Web文本的爆炸式增长和新关系的出现，人类的知识正在急剧增加，因此我们对RE提出了“更多”的要求：一个功能更强大的RE系统，它可以可靠地利用更多的数据，有效地学习更多的关系，轻松处理更复杂的上下文 ，并且可以灵活地推广到更多的开放域。 在本文中，我们回顾了现有的RE方法，分析了当今我们面临的主要挑战，并展示了朝着更强大的RE方向发展。 我们希望我们的观点能够推动这一领域的发展并激发社区的更多努力。</p><a id="more"></a><h2 id="1-介绍"><a class="markdownIt-Anchor" href="#1-介绍"></a> 1 介绍</h2><blockquote><p>Relational facts organize knowledge of the world in a triplet format. These structured facts act as an import role of human knowledge and are explicitly or implicitly hidden in the text. For example, “Steve Jobs co-founded Apple” indicates the fact (Apple Inc., founded by, Steve Jobs), and we can also infer the fact (USA, contains, New York) from “Hamilton made its debut in New York, USA”.</p></blockquote><p>关系事实以三元组的形式组织了世界知识。 这些结构化的事实充当人类知识的重要角色，并在文本中显式或隐式隐藏。 例如，“史蒂夫·乔布斯（Steve Jobs）共同创立的苹果公司”表明了事实（Apple Inc.，由史蒂夫·乔布斯（Steve Jobs）创立），我们也可以从“汉密尔顿在美国纽约首次亮相”推断出事实（美国包含纽约）。</p><blockquote><p>As these structured facts could beneﬁt downstream applications, e.g, knowledge graph completion (Bordes et al., 2013; Wang et al., 2014), search engine (Xiong et al., 2017; Schlichtkrull et al., 2018) and question answering (Bordes et al., 2014; Dong et al., 2015), many efforts have been devoted to researching relation extraction (RE), which aims at extracting relational facts from plain text. More speciﬁcally, after identifying entity mentions (e.g., USA and New York) in text, the main goal of RE is to classify relations (e.g., contains) between these entity mentions from their context.</p></blockquote><p>由于这些结构化事实可能有益于下游应用，例如知识图完成（Bordes等，2013； Wang等，2014），搜索引擎（Xiong等，2017； Schlichtkrull等，2018）和问题回答（Bordes等，2014； Dong等，2015），人们致力于研究关系提取（RE），旨在从纯文本中提取关系事实。 更具体地说，在确定文本中提及的实体（例如美国和纽约）之后，RE的主要目标是从上下文中对这些实体提及之间的关系（例如包含）进行分类。</p><blockquote><p>The pioneering explorations of RE lie in statistical approaches, such as pattern mining (Huffman, 1995; Califf and Mooney, 1997), feature-based methods (Kambhatla, 2004) and graphical models (Roth and Yih, 2002). Recently, with the development of deep learning, neural models have been widely adopted for RE (Zeng et al., 2014; Zhang et al., 2015) and achieved superior results. These RE methods have bridged the gap between unstructured text and structured knowledge, and shown their effectiveness on several public benchmarks.</p></blockquote><p>对RE的开拓性探索在于统计方法，例如模式挖掘（Huffman，1995； Califf和Mooney，1997），基于特征的方法（Kambhatla，2004）和图模型（Roth和Yih，2002）。 近年来，随着深度学习的发展，神经模型已广泛应用于RE（Zeng等，2014； Zhang等，2015），取得了较好的效果。 这些RE方法弥合了非结构化文本和结构化知识之间的鸿沟，并在一些公共基准上证明了它们的有效性。</p><blockquote><p>Despite the success of existing RE methods, most of them still work in a simpliﬁed setting. These methods mainly focus on training models with large amounts of human annotations to classify two given entities within one sentence into pre-deﬁned relations. However, the real world is much more complicated than this simple setting: (1) collecting high-quality human annotations is expensive and time-consuming, (2) many long-tail relations cannot provide large amounts of training examples, (3) most facts are expressed by long context consisting of multiple sentences, and moreover (4) using a pre-deﬁned set to cover those relations with open-ended growth is difﬁcult. Hence, to build an effective and robust RE system for real-world deployment, there are still some more complex scenarios to be further investigated.</p></blockquote><p>尽管现有的RE方法取得了成功，但大多数方法仍在简化的环境中工作。 这些方法主要集中在具有大量人工注释的训练模型上，以将一句话中的两个给定实体分类为预先定义的关系。 但是，现实世界要比这种简单设置复杂得多：（1）收集高质量的人类注释既昂贵又费时；（2）许多长尾关系无法提供大量的训练示例；（3）大多数事实由包含多个句子的长情境表达，而且（4）很难使用预先定义的集合来涵盖那些开放式增长的关系。 因此，为了实际部署构建有效而强大的RE系统，还有一些更复杂的场景需要进一步研究。</p><blockquote><p>In this paper, we review existing RE methods (Section 2) as well as latest RE explorations (Section 3) targeting more complex RE scenarios. Those feasible approaches leading to better RE abilities still require further efforts, and here we summarize them into four directions:</p></blockquote><p>在本文中，我们回顾了现有的RE方法（第2节）以及针对更复杂的RE场景的最新RE探索（第3节）。 那些导致更好的RE能力的可行方法仍然需要进一步的努力，在这里我们将它们概括为四个方向：</p><blockquote><p>(1) Utilizing More Data (Section 3.1). Supervised RE methods heavily rely on expensive human annotations, while distant supervision (Mintz et al., 2009) introduces more auto-labeled data to alleviate this issue. Yet distant methods bring noise examples and just utilize single sentences mentioning entity pairs, which signiﬁcantly weaken extraction performance. Designing schemas to obtain high-quality and high-coverage data to train robust RE models still remains a problem to be explored.</p></blockquote><p>（1）利用更多数据（第3.1节）。 监督式RE方法严重依赖于昂贵的人工注释，而远程监督（Mintz等人，2009年）引入了更多的自动标记数据来缓解这一问题。 然而，远程方法带来了噪音示例，仅使用提及实体对的单个句子，这大大削弱了提取性能。 设计模式以获取高质量和高覆盖率的数据以训练健壮的RE模型仍然是一个有待探索的问题。</p><blockquote><p>(2) Performing More Efﬁcient Learning (Section 3.2). Lots of long-tail relations only contain a handful of training examples. However, it is hard for conventional RE methods to well generalize relation patterns from limited examples like humans. Therefore, developing efﬁcient learning schemas to make better use of limited or few-shot examples is a potential research direction.</p></blockquote><p>（2）进行更有效的学习（第3.2节）。 许多长尾关系仅包含少数训练样例。 但是，传统的RE方法很难很好地概括人类等有限实例的关系模式。 因此，开发有效的学习模式以更好地利用有限几个例子是一个潜在的研究方向。</p><blockquote><p>(3) Handling More Complicated Context (Section 3.3). Many relational facts are expressed in complicated context (e.g. multiple sentences or even documents), while most existing RE models focus on extracting intra-sentence relations. To cover those complex facts, it is valuable to investigate RE in more complicated context.</p></blockquote><p>（3）处理更复杂的上下文（第3.3节）。 许多关系事实是在复杂的上下文中表达的（例如，多个句子甚至文档），而大多数现有的RE模型都侧重于提取句内关系。 为了涵盖这些复杂的事实，在更复杂的环境中研究RE是很有价值的。</p><blockquote><p>(4) Orienting More Open Domains (Section 3.4). New relations emerge every day from different domains in the real world, and thus it is hard to cover all of them by hand. However, conventional RE frameworks are generally designed for pre-deﬁned relations. Therefore, how to automatically detect undeﬁned relations in open domains remains an open problem.</p></blockquote><p>（4）面向更多开放域（第3.4节）。 每天都有来自现实世界不同领域的新关系出现，因此很难一一涵盖。 但是，常规的RE框架通常是为预先定义的关系设计的。 因此，如何自动检测开放域中未定义的关系仍然是一个悬而未决的问题。</p><blockquote><p>Besides the introduction of promising directions, we also point out two key challenges for existing methods: (1) learning from text or names (Section 4.1) and (2) datasets towards special interests (Section 4.2). We hope that all these contents could encourage the community to make further exploration and breakthrough towards better RE.</p></blockquote><p>除了介绍有希望的方向外，我们还指出了现有方法的两个主要挑战：（1）从文本或名称（第4.1节）中学习和（2）针对特殊兴趣的数据集（第4.2节）。 我们希望所有这些内容可以鼓励社区进一步探索和突破，以实现更好的RE。</p><h2 id="2-背景和现有工作"><a class="markdownIt-Anchor" href="#2-背景和现有工作"></a> 2 背景和现有工作</h2><blockquote><p>Information extraction (IE) aims at extracting structural information from unstructured text, which is an important ﬁeld in natural language processing (NLP). Relation extraction (RE), as an important task in IE, particularly focuses on extracting relations between entities. A complete relation extraction system consists of a named entity recognizer to identify named entities (e.g., people, organizations, locations) from text, an entity linker to link entities to existing knowledge graphs (KGs, necessary when using relation extraction for knowledge graph completion), and a relational classiﬁer to determine relations between entities by given context.</p></blockquote><p>信息提取（IE）旨在从非结构化文本中提取结构化信息，这是自然语言处理（NLP）中的重要领域。 关系提取（RE）作为IE中的一项重要任务，尤其着重于提取实体之间的关系。 完整的关系提取系统包括：一个命名实体识别器，用于从文本中识别命名实体（例如，人，组织，位置）；一个实体链接器，用于将实体链接到现有知识图（KG，将关系提取用于知识图完成时是必需的）；以及用于根据给定上下文确定实体之间关系的关系分类器。</p><blockquote><p>Among these steps, identifying the relation is the most crucial and difﬁcult task, since it requires models to well understand the semantics of the context. Hence, RE generally focuses on researching the classiﬁcation part, which is also known as relation classiﬁcation. As shown in Figure 1, a typical RE setting is that given a sentence with two marked entities, models need to classify the sentence into one of the pre-deﬁned relations1.</p></blockquote><p>在这些步骤中，确定关系是最关键和最困难的任务，因为它需要模型来很好地理解上下文的语义。 因此，RE通常专注于研究分类部分，这也称为关系分类。 如图1所示，典型的RE设置是给定一个带有两个标记实体的句子，模型需要将该句子分类为一种预先定义的关系1。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200520154804497.png" alt="image-20200520154804497" style="zoom:80%"><blockquote><p>In this section, we introduce the development of RE methods following the typical supervised setting, from early pattern-based methods, statistical approaches, to recent neural models.</p></blockquote><p>在本节中，我们将按照典型的监督设置介绍RE方法的发展，从早期的基于模式的方法，统计方法到最新的神经模型。</p><h3 id="21-模式提取模型"><a class="markdownIt-Anchor" href="#21-模式提取模型"></a> 2.1 模式提取模型</h3><blockquote><p>The pioneering methods use sentence analysis tools to identify syntactic elements in text, then automatically construct pattern rules from these elements (Soderland et al., 1995; Kim and Moldovan, 1995; Huffman, 1995; Califf and Mooney, 1997). In order to extract patterns with better coverage and accuracy, later work involves larger corpora (Carlson et al., 2010), more formats of patterns (Nakashole et al., 2012; Jiang et al., 2017), and more efﬁcient ways of extraction (Zheng et al., 2019). As automatically constructed patterns may have mistakes, most of the above methods require further examinations from human experts, which is the main limitation of pattern-based models.</p></blockquote><p>开创性的方法使用句子分析工具来识别文本中的句法元素，然后根据这些元素自动构建模式规则（Soderland等，1995； Kim和Moldovan，1995； Huffman，1995； Califf和Mooney，1997）。 为了提取具有更好覆盖率和准确性的模式，之后的工作涉及更大的语料库（Carlson等，2010），更多的模式格式（Nakashole等，2012； Jiang等，2017），以及更有效的提取方法（Zheng等，2019）。 由于自动构建的模式可能会出错，因此上述大多数方法都需要由专家进行进一步检查，这是基于模式的模型的主要局限性。</p><h3 id="22-统计关系提取模型"><a class="markdownIt-Anchor" href="#22-统计关系提取模型"></a> 2.2 统计关系提取模型</h3><blockquote><p>As compared to using pattern rules, statistical methods bring better coverage and require less human efforts. Thus statistical relation extraction (SRE) has been extensively studied.</p></blockquote><p>与使用模式规则相比，统计方法带来了更好的覆盖范围并且需要更少的人工。 因此，对统计关系提取（SRE）进行了广泛的研究。</p><blockquote><p>One typical SRE approach is feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Jiang and Zhai, 2007; Nguyen et al., 2007), which design lexical, syntactic and semantic features for entity pairs and their corresponding context, and then input these features into relation classiﬁers.</p></blockquote><p>一种典型的SRE方法是基于特征的方法（Kambhatla，2004； Zhou等，2005； Jiang and Zhai，2007； Nguyen等，2007），它们为实体对及其对应的上下文设计词汇，句法和语义特征 ，然后将这些特征输入到关系分类器中。</p><blockquote><p>Due to the wide use of support vector machines (SVM), kernel-based methods have been widely explored, which design kernel functions for SVM to measure the similarities between relation representations and textual instances (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Mooney and Bunescu, 2006; Zhang et al., 2006b,a; Wang, 2008).</p></blockquote><p>由于支持向量机（SVM）的广泛使用，已经广泛探索了基于内核的方法，该方法设计了SVM的核函数以测量关系表示和文本实例之间的相似性（Culotta和Sorensen，2004； Bunescu和Mooney，2005； Zhao和Grishman，2005； Mooney和Bunescu，2006； Zhang等，2006b，a； Wang，2008）。</p><blockquote><p>There are also some other statistical methods focusing on extracting and inferring the latent information hidden in the text. Graphical methods (Roth and Yih, 2002, 2004; Sarawagi and Cohen, 2005; Yu and Lam, 2010) abstract the dependencies between entities, text and relations in the form of directed acyclic graphs, and then use inference models to identify the correct relations.</p></blockquote><p>还有其他一些统计方法，着重于提取和推断隐藏在文本中的潜在信息。 图方法（Roth和Yih，2002、2004； Sarawagi和Cohen，2005； Yu和Lam，2010）以有向无环图的形式抽象实体，文本和关系之间的依赖关系，然后使用推理模型来识别正确的关系 。</p><blockquote><p>Inspired by the success of embedding models in other NLP tasks (Mikolov et al., 2013a,b), there are also efforts in encoding text into low-dimensional semantic spaces and extracting relations from textual embeddings (Weston et al., 2013; Riedel et al., 2013; Gormley et al., 2015). Furthermore, Bordes et al. (2013),Wang et al. (2014) and Lin et al. (2015) utilize KG embeddings for RE.</p></blockquote><p>受到在其他NLP任务中成功嵌入模型的启发（Mikolov等人，2013a，b），还努力将文本编码到低维语义空间中并从文本嵌入中提取关系（Weston等人，2013； Riedel 等人，2013； Gormley等人，2015）。 此外，Bordes等（2013），Wang等（2014）和Lin等（2015年）利用KG嵌入的RE。</p><blockquote><p>Although SRE has been widely studied, it still faces some challenges. Feature-based and kernel-based models require many efforts to design features or kernel functions. While graphical and embedding methods can predict relations without too much human intervention, they are still limited in model capacities. There are some surveys systematically introducing SRE models (Zelenko et al., 2003; Bach and Badaskar, 2007; Pawar et al., 2017). In this paper, we do not spend too much space for SRE and focus more on neural-based models.</p></blockquote><p>尽管对SRE进行了广泛研究，但仍然面临一些挑战。 基于特征和基于内核的模型需要付出很多努力来设计特征或核函数。 尽管图和嵌入方法可以在无需过多人工干预的情况下预测关系，但它们的模型能力仍然受到限制。 有一些调查系统地介绍了SRE模型（Zelenko等，2003; Bach和Badaskar，2007; Pawar等，2017）。 在本文中，我们不会为SRE花费太多空间，而是将更多的精力放在基于神经的模型上。</p><h3 id="23-神经关系提取模型"><a class="markdownIt-Anchor" href="#23-神经关系提取模型"></a> 2.3 神经关系提取模型</h3><blockquote><p>Neural relation extraction (NRE) models introduce neural networks to automatically extract semantic features from text. Compared with SRE models, NRE methods can effectively capture textual information and generalize to wider range of data.</p></blockquote><p>神经关系提取（NRE）模型引入了神经网络以自动从文本中提取语义特征。 与SRE模型相比，NRE方法可以有效地捕获文本信息并推广到更广泛的数据范围。</p><blockquote><p>Studies in NRE mainly focus on designing and utilizing various network architectures to capture the relational semantics within text, such as recursive neural networks (Socher et al., 2012; Miwa and Bansal, 2016) that learn compositional representations for sentences recursively, convolutional neural networks (CNNs) (Liu et al., 2013; Zeng et al., 2014; Santos et al., 2015; Nguyen and Grishman, 2015b; Zeng et al., 2015; Huang and Wang, 2017) that effectively model local textual patterns, recurrent neural networks (RNNs) (Zhang and Wang, 2015; Nguyen and Grishman, 2015a; Vu et al., 2016; Zhang et al., 2015) that can better handle long sequential data, graph neural networks (GNNs) (Zhang et al., 2018; Zhu et al., 2019a) that build word/entity graphs for reasoning, and attention-based neural networks (Zhou et al., 2016; Wang et al., 2016; Xiao and Liu, 2016) that utilize attention mechanism to aggregate global relational information.</p></blockquote><p>NRE的研究主要集中在设计和利用各种网络体系结构来捕获文本内的关系语义，例如递归神经网络（Socher等人，2012； Miwa和Bansal，2016）以递归方式学习句子的组成表示，卷积神经网络（CNN）（Liu等人，2013; Zeng等人，2014; Santos等人，2015; Nguyen和Grishman，2015b; Zeng等人，2015; Huang和Wang，2017）有效地模拟本地文本模式 ，循环神经网络（RNN）（Zhang and Wang，2015; Nguyen and Grishman，2015a; Vu et al。，2016; Zhang et al。，2015）可以更好地处理长序列数据，图神经网络（GNN）（Zhang et al。，2018; Zhu et al。，2019a）构建用于推理的词/实体图，基于注意力的神经网络（Zhou et al。，2016; Wang et al。，2016; Xiao and Liu，2016）利用注意力机制来汇总全局关系信息。</p><blockquote><p>Different from SRE models, NRE mainly utilizes word embeddings and position embeddings instead of hand-craft features as inputs. Word embeddings (Turian et al., 2010; Mikolov et al., 2013b) are the most used input representations in NLP, which encode the semantic meaning of words into vectors. In order to capture the entity information in text, position embeddings (Zeng et al., 2014) are introduced to specify the relative distances between words and entities. Except for word embeddings and position embeddings, there are also other works integrating syntactic information into NRE models. Xu et al. (2015a) and Xu et al. (2015b) adopt CNNs and RNNs over shortest dependency paths respectively. Liu et al. (2015) propose a recursive neural network based on augmented dependency paths. Xu et al. (2016) and Cai et al. (2016) utilize deep RNNs to make further use of dependency paths. Besides, there are some efforts combining NRE with universal schemas (Verga et al., 2016; Verga and McCallum, 2016; Riedel et al., 2013). Recently, Transformers (Vaswani et al., 2017) and pre-trained language models (Devlin et al., 2019) have also been explored for NRE (Du et al., 2018; Verga et al., 2018; Wu and He, 2019; Baldini Soares et al., 2019) and have achieved new state-of-the-arts.</p></blockquote><p>与SRE模型不同，NRE主要利用单词嵌入和位置嵌入代替输入的手工特征。词嵌入（Turian等人，2010； Mikolov等人，2013b）是NLP中使用最多的输入表示，它将单词的语义含义编码为向量。为了在文本中捕获实体信息，引入了位置嵌入（Zeng等，2014）来指定单词和实体之间的相对距离。除了单词嵌入和位置嵌入，还有其他将语法信息集成到NRE模型中的工作。徐等（2015a）和Xu等（2015b）分别在最短依赖路径上采用了CNN和RNN。刘等（2015）提出了一种基于增强依赖路径的递归神经网络。徐等（2016）和Cai等（2016）利用深层RNN来进一步利用依赖路径。此外，还有一些努力将NRE与通用模式结合起来（Verga等人，2016; Verga和McCallum，2016; Riedel等人，2013）。最近，针对NRE也探索了转换器（Vaswani等人，2017）和预训练语言模型（Devlin等人，2019）（Du等人，2018; Verga等人，2018; Wu和He， 2019; Baldini Soares等人，2019）并取得了新的最新技术水平。</p><blockquote><p>By concisely reviewing the above techniques, we are able to track the development of RE from pattern and statistical methods to neural models. Comparing the performance of state-of-the-art RE models in years (Figure 2), we can see the vast increase since the emergence of NRE, which demonstrates the power of neural methods.</p></blockquote><p>通过简要回顾上述技术，我们能够跟踪RE从模式和统计方法到神经模型的发展。 比较多年来最先进的RE模型的性能（图2），我们可以看到自从NRE出现以来的巨大增长，这证明了神经方法的强大。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521163831666.png" alt="图2" style="zoom:80%"><h2 id="3-re的更多方向"><a class="markdownIt-Anchor" href="#3-re的更多方向"></a> 3 RE的“更多”方向</h2><blockquote><p>Although the above-mentioned NRE models have achieved superior results on benchmarks, they are still far from solving the problem of RE. Most of these models utilize abundant human annotations and just aim at extracting pre-deﬁned relations within single sentences. Hence, it is hard for them to work well in complex cases. In fact, there have been various works exploring feasible approaches that lead to better RE abilities on realworld scenarios. In this section, we summarize these exploratory efforts into four directions, and give our review and outlook about these directions.</p></blockquote><p>尽管上述NRE模型在基准测试中取得了优异的结果，但距离解决RE问题还差很远。 这些模型中的大多数都利用了丰富的人工注释，并且仅旨在提取单个句子中的预定义关系。 因此，他们很难在复杂的情况下工作。 实际上，已经有各种各样的工作在探索可行的方法，这些方法可以在现实世界中实现更好的RE能力。 在本节中，我们将这些探索性工作总结为四个方向，并对这些方向进行回顾和展望。</p><h3 id="31-利用更多数据"><a class="markdownIt-Anchor" href="#31-利用更多数据"></a> 3.1 利用更多数据</h3><blockquote><p>Supervised NRE models suffer from the lack of large-scale high-quality training data, since manually labeling data is time-consuming and human-intensive. To alleviate this issue, distant supervision (DS) assumption has been used to automatically label data by aligning existing KGs with plain text (Mintz et al., 2009; Nguyen and Moschitti, 2011; Min et al., 2013). As shown in Figure 3, for any entity pair in KGs, sentences mentioning both the entities will be labeled with their corresponding relations in KGs. Large-scale training examples can be easily constructed by this heuristic scheme.</p></blockquote><p>有监督的NRE模型缺乏大规模的高质量训练数据，因为手动标记数据既费时又费力。 为了缓解这个问题，远程监督（DS）假设已用于通过将现有KG与纯文本对齐来自动标记数据（Mintz等，2009； Nguyen和Moschitti，2011； Min等，2013）。 如图3所示，对于KG中的任何实体对，提及两个实体的句子将在KG中标有它们的对应关系。 通过这种启发式方案可以轻松构建大规模的训练样例。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521164416374.png" alt="图3" style="zoom:80%"><blockquote><p>Although DS provides a feasible approach to utilize more data, this automatic labeling mechanism is inevitably accompanied by the wrong labeling problem. The reason is that not all sentences mentioning the two entities express their relations in KGs exactly. For example, we may mistakenly label “Bill Gates retired from Microsoft” with the relation founder, if (Bill Gates, founder, Microsoft) is a relational fact in KGs.</p></blockquote><p>尽管DS提供了一种利用更多数据的可行方法，但是这种自动标记机制不可避免地会伴随着错误标记的问题。 原因是并非所有提及这两个实体的句子都精确地表示了它们之间的关系。 例如，如果（比尔·盖茨，创始人，微软）在KG中是一个关系事实，我们可能会错误地用关系创始人标记“从微软退休的比尔·盖茨”。</p><blockquote><p>The existing methods to alleviate the noise problem can be divided into three major approaches:</p></blockquote><p>减轻噪声问题的现有方法可以分为三种主要方法：</p><blockquote><p>(1) Some methods adopt multi-instance learning by combining sentences with same entity pairs and then selecting informative instances from them. Riedel et al. (2010); Hoffmann et al. (2011); Surdeanu et al. (2012) utilize graphical model to infer the informative sentences, while Zeng et al. (2015) use a simple heuristic selection strategy. Later on, Lin et al. (2016); Zhang et al. (2017); Han et al. (2018c); Li et al. (2019); Zhu et al. (2019c); Hu et al. (2019) design attention mechanisms to highlight informative instances for RE.</p></blockquote><p>（1）有些方法采用多实例学习，即将具有相同实体对的句子组合在一起，然后从中选择信息实例。 Riedel等（2010）； 霍夫曼等（2011）； Surdeanu等（2012年）利用图模型来推断信息句子，而Zeng等（2015年）使用简单的启发式选择策略。 后来，Lin等（2016）； 张等（2017）; Han等（2018c）; Li等（2019）; 朱等（2019c）; Hu等（2019）设计注意力机制以突出RE的信息实例。</p><blockquote><p>(2) Incorporating extra context information to denoise DS data has also been explored, such as incorporating KGs as external information to guide instance selection (Ji et al., 2017; Han et al., 2018b; Zhang et al., 2019a; Qu et al., 2019) and adopting multi-lingual corpora for the information consistency and complementarity (Verga et al., 2016; Lin et al., 2017; Wang et al., 2018).</p></blockquote><p>（2）探索将额外的上下文信息用于降噪DS数据的方法，例如将KG用作外部信息来指导实例选择（Ji等人，2017; Han等人，2018b; Zhang等人，2019a; Qu 等人，2019），并采用多语言语料库来实现信息的一致性和互补性（Verga等人，2016; Lin等人，2017; Wang等人，2018）。</p><blockquote><p>(3) Many methods tend to utilize sophisticated mechanisms and training strategies to enhance distantly supervised NRE models. Vu et al. (2016); Beltagy et al. (2019) combine different architectures and training strategies to construct hybrid frameworks. Liu et al. (2017) incorporate a softlabel scheme by changing unconﬁdent labels during training. Furthermore, reinforcement learning (Feng et al., 2018; Zeng et al., 2018) and adversarial training (Wu et al., 2017; Wang et al., 2018; Han et al., 2018a) have also been adopted in DS.</p></blockquote><p>（3）许多方法倾向于利用复杂的机制和训练策略来增强远程监督的NRE模型。 Vu等（2016）； Beltagy等（2019）结合了不同的架构和培训策略来构建混合框架。 刘等（2017）通过在训练期间更改不一致标签来合并软标签方案。 此外，强化学习（Feng等，2018; Zeng等，2018）和对抗训练（Wu等，2017; Wang等，2018; Han等，2018a）也已在DS中被采用 。</p><blockquote><p>The researchers have formed a consensus that utilizing more data is a potential way towards more powerful RE models, and there still remains some open problems worth exploring:</p></blockquote><p>研究人员已经达成共识，即利用更多数据是建立更强大的RE模型的潜在途径，但仍然存在一些值得探讨的未解决问题：</p><blockquote><p>(1) Existing DS methods focus on denoising auto-labeled instances and it is certainly meaningful to follow this research direction. Besides, current DS schemes are still similar to the original one in (Mintz et al., 2009), which just covers the case that the entity pairs are mentioned in the same sentences. To achieve better coverage and less noise, exploring better DS schemes for autolabeling data is also valuable.</p></blockquote><p>（1）现有的DS方法着重于对自动标记的实例进行去噪，遵循这一研究方向无疑是有意义的。 此外，当前的DS方案仍然与（Mintz等，2009）中的原始DS方案相似，后者仅涵盖了在同一句子中提到实体对的情况。 为了获得更好的覆盖范围和更少的噪声，探索更好的DS方案以自动标记数据也很有价值。</p><blockquote><p>(2) Inspired by recent work in adopting pre-trained language models (Zhang et al., 2019b; Wu and He, 2019; Baldini Soares et al., 2019) and active learning (Zheng et al., 2019) for RE, to perform unsupervised or semi-supervised learning for utilizing large-scale unlabeled data as well as using knowledge from KGs and introducing human experts in the loop is also promising.</p></blockquote><p>（2）受最近RE采用预训练语言模型（Zhang等人，2019b; Wu和He，2019; Baldini Soares等人，2019）以及主动学习（Zheng等人，2019）的启发，利用大型未标记数据以及使用KG中的知识并在循环中引入人类专家的无监督或半监督学习也很有希望。</p><blockquote><p>Besides addressing existing approaches and future directions, we also propose a new DS dataset to advance this ﬁeld, which will be released once the paper is published. The most used benchmark for DS, NYT-10 (Riedel et al., 2010), suffers from small amount of relations, limited relation domains and extreme long-tail relation performance. To alleviate these drawbacks, we utilize Wikipedia and Wikidata (Vrandeˇ cic´ and Kr¨ otzsch, 2014) to construct Wiki-Distant in the same way as Riedel et al. (2010). As demonstrated in Table 1, WikiDistant covers more relations and possesses more instances, with a more reasonable N/A proportion. Comparison results of state-of-the-art models on these two datasets2 are shown in Table 2, indicating that Wiki-Distant is more challenging and there is a long way to resolve distantly supervised RE.</p></blockquote><p>除了解决现有方法和未来方向外，我们还提出了一个新的DS数据集来推进这一领域的发展，该数据将在论文发表后发布。 DS中使用最多的基准，即NYT-10（Riedel等，2010），其关系数量少，关系域有限，长尾关系性能极高。 为了减轻这些弊端，我们利用Wikipedia和Wikidata（Vrandeˇ cic´和Krótzch，2014）以与Riedel等人（2010）相同的方式构建Wiki-Distant。 如表1所示，WikiDistant涵盖了更多的关系并拥有更多的实例，并且具有更合理的N / A比例。 表2显示了这两个数据集上的最新模型的比较结果，表明Wiki-Distant更具挑战性，解决远程监督的RE有很长的路要走。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521170849835.png" alt="表1" style="zoom:80%"> <img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521170909088.png" alt="表2" style="zoom:80%"><h3 id="32-进行更有效的学习"><a class="markdownIt-Anchor" href="#32-进行更有效的学习"></a> 3.2 进行更有效的学习</h3><blockquote><p>Real-world relation distributions are long-tail: Only the common relations obtain sufﬁcient training instances and most relations have very limited relational facts and corresponding sentences. We can see the long-tail relation distributions on two DS datasets from Figure 4, where many relations even have less than 10 training instances. This phenomenon calls for models that can learn longtail relations more efﬁciently. Few-shot learning, which focuses on grasping tasks with only a few training examples, is a good ﬁt for this need.</p></blockquote><p>现实世界中的关系分布是长尾的：只有常见关系才能获得足够的训练实例，大多数关系具有非常有限的关系事实和相应的句子。 我们可以从图4中看到两个DS数据集上的长尾关系分布，其中许多关系甚至少于10个训练实例。 这种现象要求模型可以更有效地学习长尾关系。 小样本学习专注于仅通过几个训练样例就可以完成任务，因此非常适合这种需求。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521171507693.png" alt="图4" style="zoom:80%"><blockquote><p>To advance this ﬁeld, Han et al. (2018d) ﬁrst built a large-scale few-shot relation extraction dataset (FewRel). This benchmark takes the N-way K-shot setting, where models are given N random-sampled new relations, along with K training examples for each relation. With limited information, RE models are required to classify query instances into given relations (Figure 5).</p></blockquote><p>为了提高这一领域，Han等人（2018d）首先建立了一个大规模的小样本关系提取数据集（FewRel）。 该基准采用N路K样本设置，其中为模型提供了N个随机采样的新关系，以及每个关系的K个训练样本。 在信息有限的情况下，需要使用RE模型将查询实例分类为给定的关系（图5）。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200521171942728.png" alt="图5" style="zoom:80%"><blockquote><p>The general idea of few-shot models is to train good representations of instances or learn ways of fast adaptation from existing large-scale data, and then transfer to new tasks. There are mainly two ways for handling few-shot learning: (1) learns a semantic metric on existing data and classiﬁes queries by comparing them with training examples (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Baldini Soares et al., 2019). While most metric learning models perform distance measurement on sentence-level representation, Ye and Ling (2019); Gao et al. (2019) utilize token-level attention for ﬁner-grained comparison. (2) Meta-learning, also known as “learning to learn”, aims at grasping the way of parameter initialization and optimization through the experience gained on the meta-train data (Ravi and Larochelle, 2017; Finn et al., 2017; Mishra et al., 2018).</p></blockquote><p>小样本模型的总体思想是从现有的大规模数据中训练实例的良好表示或学习快速适应的方法，然后转移到新任务上。 处理小样本学习的方法主要有两种：（1）度量学习通过将现有数据与训练示例进行比较来学习现有数据的语义度量，并对查询进行分类（Koch等，2015； Vinyals等，2016； Snell等人，2017年； Baldini Soares等人，2019年）。 虽然大多数度量学习模型都对句子级表示进行距离测量，但Ye和Ling（2019）; Gao等（2019）利用令牌级注意进行细粒度的比较。 （2）元学习，也被称为“learning to learn”，旨在通过在元训练数据上获得的经验来掌握参数初始化和优化的方式（Ravi和Larochelle，2017； Finn等，2017； Rev。 Mishra等人，2018）。</p><blockquote><p>Researchers have made great progress in few-shot RE. However, there remain many challenges that are important for its applications and have not yet been discussed. Gao et al. (2019) propose two problems worth further investigation:</p></blockquote><p>研究人员在小样本RE中取得了长足的进步。 但是，仍然存在许多对其应用很重要的挑战尚未讨论。 Gao等（2019）提出了两个值得进一步研究的问题：</p><blockquote><p>(1) Few-shot domain adaptation studies how few-shot models can transfer across domains . It is argued that in the real-world application, the test domains are typically lacking annotations and could differ vastly from the training domains. Thus, it is crucial to evaluate the transferabilities of few-shot models across domains.</p></blockquote><p>（1）小样本域自适应研究了小样本模型如何跨域转移。 有人认为，在实际应用中，测试域通常缺少注释，并且可能与训练域有很大差异。 因此，至关重要的是评估小样本模型跨域的可传递性。</p><blockquote><p>(2) Few-shot none-of-the-above detection is about detecting query instances that do not belong to any of the sampled N relations. In the N-way K-shot setting, it is assumed that all queries express one of the given relations. However, the real case is that most sentences are not related to the relations of our interest. Conventional few-shot models cannot well handle this problem due to the difﬁculty to form a good representation for the none-of-the-above (NOTA) relation. Therefore, it is crucial to study how to identify NOTA instances.</p></blockquote><p>（2）小样本非上述检测是关于检测不属于任何采样N个关系的查询实例。 在N路K样本设置中，假定所有查询都表达给定关系之一。 但是，实际情况是，大多数句子与我们感兴趣的关系无关。 常规的小样本模型不能很好地处理此问题，原因是很难形成非上述（NOTA）关系的良好表示。 因此，研究如何识别NOTA实例至关重要。</p><blockquote><p>(3) Besides the above challenges, it is also important to see that, the existing evaluation protocol may over-estimate the progress we made on few-shot RE. Unlike conventional RE tasks, few-shot RE randomly samples N relations for each evaluation episode; in this setting, the number of relations is usually very small (5 or 10) and it is very likely to sample N distinct relations and thus reduce to a very easy classiﬁcation task.</p></blockquote><p>（3）除了上述挑战外，还必须看到，现有评估协议可能会高估我们在小样本RE方面取得的进展。 与常规的RE任务不同，小样本RE为每个评估情节随机采样N个关系。 在这种情况下，关系的数量通常很少（5或10），并且很有可能对N个不同的关系进行采样，从而简化为非常简单的分类任务。</p><blockquote><p>We carry out two simple experiments to show the problems (Figure 6): (A) We evaluate few-shot models with increasing N and the performance drops drastically with larger relation numbers. Considering that the real-world case contains much more relations, it shows that existing models are still far from being applied. (B) Instead of randomly sampling N relations, we hand-pick 5relations similar in semantics and evaluate few-shot RE models on them. It is no surprise to observe a sharp decrease in the results, which suggests that existing few-shot models may overﬁt simple textual cues between relations instead of really understanding the semantics of the context. More details about the experiments are in Appendix A.</p></blockquote><p>我们进行了两个简单的实验来显示问题（图6）：（A）我们评估了N增加时的小样本模型，而关系数越大，性能急剧下降。 考虑到实际案例中包含的关系更多，这表明现有模型仍远未应用。 （B）我们不是随机抽样N个关系，而是手动选择语义上相似的5个关系，并评估它们上的小样本RE模型。 观察到结果急剧下降也就不足为奇了，这表明现有的小样本模型可能会掩盖关系之间的简单文本提示，而不是真正理解上下文的语义。 有关实验的更多详细信息，请参见附录A。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522172838258.png" alt="图6" style="zoom:80%"><h3 id="33-处理更复杂的上下文"><a class="markdownIt-Anchor" href="#33-处理更复杂的上下文"></a> 3.3 处理更复杂的上下文</h3><blockquote><p>As shown in Figure 7, one document generally mentions many entities exhibiting complex cross-sentence relations. Most existing methods focus on intra-sentence RE and thus are inadequate for collectively identifying these relational facts expressed in a long paragraph. In fact, most relational facts can only be extracted from complicated context like documents rather than single sentences (Yao et al., 2019), which should not be neglected.</p></blockquote><p>如图7所示，一份文件通常提到许多表现出复杂跨句关系的实体。 现有的大多数方法都集中在句内的RE，因此不足以集体识别较长段落中表达的这些关系事实。 实际上，大多数关系事实只能从文档之类的复杂语境中提取，而不能从单个句子中提取（Yao等人，2019），这一点不容忽视。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522181458763.png" alt="图7" style="zoom:80%"><blockquote><p>There are already some works proposed to extract relations across multiple sentences:</p></blockquote><p>已经有提出了一些工作来提取多个句子之间的关系：</p><blockquote><p>(1) Syntactic methods (Wick et al., 2006; Gerber and Chai, 2010; Swampillai and Stevenson, 2011; Yoshikawa et al., 2011; Quirk and Poon, 2017) rely on textual features extracted from various syntactic structures, such as coreference annotations, dependency parsing trees and discourse relations, to connect sentences in documents.</p></blockquote><p>（1）句法方法（Wick等，2006; Gerber和Chai，2010; Swampillai和Stevenson，2011; Yoshikawa等，2011; Quirk和Poon，2017）依赖于从各种句法结构中提取的文本特征，例如共指注释，依赖关系分析树和语篇关系，以连接文档中的句子。。</p><blockquote><p>(2) Zeng et al. (2017); Christopoulou et al (2018) build inter-sentence entity graphs, which can utilize multi-hop paths between entities for inferring the correct relations.</p></blockquote><p>（2）Zeng等（2017）; Christopoulou等（2018）建立了句间实体图，该图可以利用实体之间的多跳路径来推断正确的关系。</p><blockquote><p>(3) Peng et al. (2017); Song et al. (2018); Zhu et al. (2019b) employ graph-structured neural networks to model cross-sentence dependencies for relation extraction, which bring in memory and reasoning abilities.</p></blockquote><p>（3）彭等（2017）; 宋等（2018）; 朱等（2019b）使用图结构神经网络为跨句依赖关系建模以提取关系，从而引入了记忆和推理能力。</p><blockquote><p>To advance this ﬁeld, some document-level RE datasets have been proposed. Quirk and Poon (2017); Peng et al. (2017) build datasets by DS Li et al. (2016); Peng et al. (2017) propose datasets for speciﬁc domains. Yao et al. (2019) construct a general document-level RE dataset annotated by crowdsourcing workers, suitable for evaluating general-purpose document-level RE systems.</p></blockquote><p>为了提高这一领域，已经提出了一些文档级的RE数据集。Quirk和Poon（2017）; Peng等（2017）由DS建立数据集。 Li等（2016）； Peng等（2017）提出了特定领域的数据集。 Yao等（2019）构建了一个由众包工作者注释的通用文档级RE数据集，适用于评估通用文档级RE系统。</p><blockquote><p>Although there are some efforts investing into extracting relations from complicated context (e.g., documents), the current RE models for this challenge are still crude and straightforward. Followings are some directions worth further investigation:</p></blockquote><p>尽管已进行了一些努力来从复杂的上下文（例如文档）中提取关系，但是当前针对此挑战的RE模型仍然是粗糙而直接的。 以下是一些值得进一步研究的方向：</p><blockquote><p>(1) Extracting relations from complicated context is a challenging task requiring reading, memorizing and reasoning for discovering relational facts across multiple sentences. Most of current RE models are still very weak in these abilities.</p></blockquote><p>（1）从复杂的上下文中提取关系是一项艰巨的任务，需要阅读，记忆和推理才能发现多个句子中的关系事实。 当前大多数RE模型在这些能力上仍然非常薄弱。</p><blockquote><p>(2) Besides documents, more forms of context is also worth exploring, such as extracting relational facts across documents, or understanding relational information based on heterogeneous data.</p></blockquote><p>（2）除了文档之外，还需要探索更多形式的上下文，例如跨文档提取关系事实，或基于异构数据理解关系信息。</p><blockquote><p>(3) Inspired by Narasimhan et al. (2016), which utilizes search engines for acquiring external information, automatically searching and analysing context for RE may help RE models identify relational facts with more coverage and become practical for daily scenarios.</p></blockquote><p>（3）受Narasimhan等人（2016年）启发，利用搜索引擎获取外部信息，自动搜索和分析RE的上下文，可以帮助RE模型识别涉及范围更广的关系事实，并适用于日常场景。</p><h3 id="34-定向更多开放域"><a class="markdownIt-Anchor" href="#34-定向更多开放域"></a> 3.4 定向更多开放域</h3><blockquote><p>Most RE systems work within pre-speciﬁed relation sets designed by human experts. However, our world undergoes open-ended growth of relations and it is not possible to handle all these emerging relation types only by humans. Thus, we need RE systems that do not rely on pre-deﬁned relation schemas and can work in open scenarios.</p></blockquote><p>大多数RE系统在人类专家设计的预定关系集中工作。 但是，我们的世界正在经历关系的开放式增长，不可能仅靠人类来处理所有这些新兴关系类型。 因此，我们需要不依赖于预先定义的关系模式并且可以在开放方案中工作的RE系统。</p><blockquote><p>There are already some explorations in handling open relations: (1) Open information extraction (Open IE), as shown in Figure 8, extracts relation phrases and arguments (entities) from text (Banko et al., 2007; Fader et al., 2011; Mausam et al., 2012; Del Corro and Gemulla, 2013; Angeli et al., 2015; Stanovsky and Dagan, 2016; Mausam, 2016; Cui et al., 2018). Open IE does not rely on speciﬁc relation types and thus can handle all kinds of relational facts. (2) Relation discovery, as shown in Figure 9, aims at discovering unseen relation types from unsupervised data. Yao et al. (2011); Marcheggiani and Titov (2016) propose to use generative models and treat these relations as latent variables, while Shinyama and Sekine (2006); Elsahar et al. (2017); Wu et al. (2019) cast relation discovery as a clustering task.</p></blockquote><p>在处理开放关系方面已经进行了一些探索：（1）开放信息提取（Open IE），如图8所示，从文本中提取关系短语和自变量（实体）（Banko等，2007； Fader等， 2011; Mausam等，2012; Del Corro和Gemulla，2013; Angeli等，2015; Stanovsky和Dagan，2016; Mausam，2016; Cui等，2018）。 开放式IE不依赖于特定的关系类型，因此可以处理各种关系事实。 （2）关系发现，如图9所示，旨在从无监督的数据中发现看不见的关系类型。 姚等（2011）； Marcheggiani和Titov（2016）提出使用生成模型并将这些关系视为潜在变量，而Shinyama和Sekine（2006）；Elsahar等（2017）; Wu等（2019）则提出将关系发现作为聚类任务。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522220121510.png" alt="图8" style="zoom:80%"> <img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522220242588.png" alt="图9" style="zoom:80%"><blockquote><p>Though relation extraction in open domains has been widely studied, there are still lots of unsolved research questions remained to be answered:</p></blockquote><p>尽管对开放域中的关系提取进行了广泛的研究，但仍有许多未解决的研究问题尚待解答：</p><blockquote><p>(1) Canonicalizing relation phrases and arguments in Open IE is crucial for downstream tasks (Niklaus et al., 2018). If not canonicalized, the extracted relational facts could be redundant and ambiguous. For example, Open IE may extract two triples (Barack Obama, was born in, Honolulu) and (Obama, place of birth, Honolulu) indicating an identical fact. Thus, normalizing extracted results will largely beneﬁt the applications of Open IE. There are already some preliminary works in this area (Gal´ arraga et al., 2014; Vashishth et al., 2018) and more efforts are needed.</p></blockquote><p>（1）在Open IE中规范化关系短语和参数对于下游任务至关重要（Niklaus等，2018）。 如果不规范，提取的关系事实可能是多余的和不明确的。 例如，Open IE可能会提取两个三元组（巴拉克·奥巴马，出生于，檀香山）和（奥巴马，出生地，檀香山），表示相同的事实。 因此，标准化提取结果将在很大程度上有利于Open IE的应用。 该领域已经有一些初步工作（Gal´arraga等人，2014； Vashishth等人，2018），还需要更多的努力。</p><blockquote><p>(2) The not applicable (N/A) relation has been hardly addressed in relation discovery. In previous work, it is usually assumed that the sentence always expresses a relation between the two entities (Marcheggiani and Titov, 2016). However, in the real-world scenario, a large proportion of entity pairs appearing in a sentence do not have a relation, and ignoring them or using simple heuristics to get rid of them may lead to poor results. Thus, it would be of interest to study how to handle these N/A instances in relation discovery.</p></blockquote><p>（2）在关系发现中几乎未解决不适用（N / A）关系。 在先前的工作中，通常假设该句子始终表示两个实体之间的关系（Marcheggiani和Titov，2016）。 但是，在现实世界中，句子中出现的大部分实体对没有关系，而忽略它们或使用简单的启发式方法摆脱它们又可能会导致不良结果。 因此，研究如何在关系发现中处理这些N / A实例将引起人们的兴趣。</p><h2 id="4-其他挑战"><a class="markdownIt-Anchor" href="#4-其他挑战"></a> 4 其他挑战</h2><blockquote><p>In this section, we analyze two key challenges faced by RE models, address them with experiments and show their signiﬁcance in the research and development of RE systems.</p></blockquote><p>在本节中，我们分析RE模型面临的两个主要挑战，通过实验解决这些挑战，并展示它们在RE系统研究和开发中的重要性。</p><h3 id="41-从文字或名称中学习"><a class="markdownIt-Anchor" href="#41-从文字或名称中学习"></a> 4.1 从文字或名称中学习</h3><blockquote><p>In the process of RE, both entity names and their context provide useful information for classiﬁcation. Entity names provide typing information (e.g., we can easily tell JFK International Airport is an airport) and help to narrow down the range of possible relations; In the training process, entity embeddings may also be formed to help relation classiﬁcation (like in the link prediction task of KG). On the other hand, relations can usually be extracted from the semantics of text around entity pairs. In some cases, relations can only be inferred implicitly by reasoning over the context.</p></blockquote><p>在RE的过程中，实体名称及其上下文均提供了有用的分类信息。 实体名称提供了键入信息（例如，我们可以很容易地分辨出肯尼迪国际机场是一个机场），并有助于缩小可能的关系范围； 在训练过程中，也可以形成实体嵌入来帮助关系分类（例如在KG的链接预测任务中）。 另一方面，通常可以从实体对周围的文本语义中提取关系。 在某些情况下，只能通过对上下文进行推理来隐式推断关系。</p><blockquote><p>Since there are two sources of information, it is interesting to study how much each of them contributes to the RE performance. Therefore, we design three different settings for the experiments: (1) normal setting, where both names and text are taken as inputs; (2) masked-entity (ME) setting, where entity names are replaced with a special token; (3) only-entity (OE) setting, where only names of the two entities are provided.</p></blockquote><p>由于有两种信息来源，因此有趣的是研究它们各自对RE绩效的贡献。 因此，我们为实验设计了三种不同的设置：（1）常规设置，其中名称和文本均作为输入； （2）屏蔽实体（ME）设置，其中实体名称被替换为特殊标记； （3）仅实体（OE）设置，其中仅提供两个实体的名称。</p><blockquote><p>Results from Table 3 show that compared to the normal setting, models suffer a huge performance drop in both the ME and OE settings. Besides, it is surprising to see that in most cases, only using entity names outperforms only using text with entities masked. It suggests that (1) both entity names and text provide crucial information for RE, and (2) for existing state-of-the-art models and benchmarks, entity names contribute even more.</p></blockquote><p>表3的结果表明，与正常设置相比，模型的ME和OE设置均遭受巨大的性能下降。 此外，令人惊讶的是，在大多数情况下，仅使用实体名称会优于仅使用带有被屏蔽实体的文本。 它表明（1）实体名称和文本都为RE提供了关键信息，（2）对于现有的最新模型和基准，实体名称的贡献更大。</p><img src="assert/2020-More%20Data,%20More%20Relations,%20More%20Context%20and%20More%20Openness%20A%20Review%20and%20Outlook%20for%20Relation%20Extraction.assert/image-20200522221910288.png" alt="表3" style="zoom:80%"><blockquote><p>The observation is contrary to human intuition: we classify the relations between given entities mainly from the text description, yet models learn more from their names. To make real progress in understanding how language expresses relational facts, this problem should be further investigated and more efforts are needed.</p></blockquote><p>该观察结果与人类的直觉相反：我们主要根据文本描述对给定实体之间的关系进行分类，而模型则从其名称中学习更多。 为了在理解语言如何表达关系事实方面取得真正的进步，应该进一步研究这个问题，并且需要付出更多的努力。</p><h3 id="42-针对特殊兴趣的re数据集"><a class="markdownIt-Anchor" href="#42-针对特殊兴趣的re数据集"></a> 4.2 针对特殊兴趣的RE数据集</h3><blockquote><p>There are already many datasets that beneﬁt RE research: For supervised RE, there are MUC (Grishman and Sundheim, 1996), ACE-2005 (Ntroduction, 2005), SemEval-2010 Task 8 (Hendrickx et al., 2009), KBP37 (Zhang and Wang, 2015) and TACRED (Zhang et al., 2017); and we have NYT10 (Riedel et al., 2010), FewRel (Han et al., 2018d) and DocRED (Yao et al., 2019) for distant supervision, few-shot and document-level RE respectively.</p></blockquote><p>已经有许多可用于RE研究的数据集：对于有监督RE，有MUC（Grishman和Sundheim，1996），ACE-2005（Ntroduction，2005），SemEval-2010 Task 8（Hendrickx等人，2009），KBP37（ Zhang and Wang，2015）和TACRED（Zhang et al。，2017）; 我们有NYT10（Riedel等人，2010），FewRel（Han等人，2018d）和DocRED（Yao等人，2019）分别用于远程监管，小样本和文档级RE。</p><blockquote><p>However, there are barely datasets targeting special problems of interest. For example, RE across sentences (e.g., two entities are mentioned in two different sentences) is an important problem, yet there is no speciﬁc datasets that can help researchers study it. Though existing document-level RE datasets contain instances of this case, it is hard to analyze the exact performance gain towards this speciﬁc aspect. Usually, researchers (1) use handcrafted sub-sets of general datasets or (2) carry out case studies to show the effectiveness of their models in speciﬁc problems, which is lacking of convincing and quantitative analysis. Therefore, to further study these problems of great importance in the development of RE, it is necessary for the community to construct well-recognized, well-designed and ﬁne-grained datasets towards special interests.</p></blockquote><p>但是，几乎没有针对特殊问题的数据集。 例如，跨句子的RE（例如，两个实体在两个不同的句子中提到了）是一个重要的问题，但是没有特定的数据集可以帮助研究人员对其进行研究。 尽管现有的文档级RE数据集包含这种情况的实例，但是很难分析针对此特定方面的确切性能提升。 通常，研究人员（1）使用手工制作的一般数据集的子集，或者（2）进行案例研究以显示其模型在特定问题上的有效性，而这些问题缺乏令人信服的定量分析。 因此，为了进一步研究这些在RE发展中非常重要的问题，社区有必要构建针对特殊兴趣的，公认的，设计良好的和细粒度的数据集。</p><h2 id="5-结论"><a class="markdownIt-Anchor" href="#5-结论"></a> 5 结论</h2><blockquote><p>In this paper, we give a comprehensive and detailed review on the development of relation extraction models, generalize four promising directions leading to more powerful RE systems (utilizing more data, performing more efﬁcient learning, handling more complicated context and orienting more open domains), and further investigate two key challenges faced by existing RE models. We thoroughly survey the previous RE literature as well as supporting our points with statistics and experiments. Through this paper, we hope to demonstrate the progress and problems in existing RE research and encourage more efforts in this area.</p></blockquote><p>在本文中，我们对关系提取模型的开发进行了全面而详细的综述，概括了四个有希望的方向，这些方向导致了功能更强大的RE系统（利用更多的数据，执行更有效的学习，处理更复杂的上下文以及定向更多的开放域）， 并进一步研究现有RE模型面临的两个关键挑战。 我们会彻底调查以前的RE文献，并通过统计和实验来支持我们的观点。 通过本文，我们希望展示现有RE研究的进展和存在的问题，并鼓励在这一领域做出更多努力。</p></div><footer class="post-footer"><div class="post-tags"><a href="/tags/paper/" rel="tag"><i class="fa fa-tag"></i> paper</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2020/04/22/papers/2020-A%20new%20rule%20reduction%20and%20training%20method%20for%20extended%20belief%20rule%20base%20based%20on%20DBSCAN%20algorithm/" rel="prev" title="2020-A new rule reduction and training method for extended belief rule base based on DBSCAN algorithm"><i class="fa fa-chevron-left"></i> 2020-A new rule reduction and training method for extended belief rule base based on DBSCAN algorithm</a></div><div class="post-nav-item"></div></div></footer></article></div></div><script>window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#摘要"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-介绍"><span class="nav-number">2.</span> <span class="nav-text">1 介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-背景和现有工作"><span class="nav-number">3.</span> <span class="nav-text">2 背景和现有工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#21-模式提取模型"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 模式提取模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#22-统计关系提取模型"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 统计关系提取模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#23-神经关系提取模型"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 神经关系提取模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-re的更多方向"><span class="nav-number">4.</span> <span class="nav-text">3 RE的“更多”方向</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#31-利用更多数据"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 利用更多数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#32-进行更有效的学习"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 进行更有效的学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#33-处理更复杂的上下文"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 处理更复杂的上下文</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#34-定向更多开放域"><span class="nav-number">4.4.</span> <span class="nav-text">3.4 定向更多开放域</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-其他挑战"><span class="nav-number">5.</span> <span class="nav-text">4 其他挑战</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#41-从文字或名称中学习"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 从文字或名称中学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#42-针对特殊兴趣的re数据集"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 针对特殊兴趣的RE数据集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-结论"><span class="nav-number">6.</span> <span class="nav-text">5 结论</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="M1saki" src="/images/avatar_1.jpg"><p class="site-author-name" itemprop="name">M1saki</p><div class="site-description" itemprop="description">不要低估你的能力<br>不要高估你的毅力</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">15</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">12</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">M1saki</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">155k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">2:21</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><canvas id="canvas"></canvas></body></html>